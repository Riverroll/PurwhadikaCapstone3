{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context:\n",
    "In the telecommunications industry, customer churn is a significant concern as it directly impacts revenue and profitability. The dataset represents customer profiles of those who have left a telco company. Understanding the factors that contribute to customer churn can help the company develop strategies to retain existing customers and improve overall customer satisfaction.\n",
    "\n",
    "### Problem Statement:\n",
    "The telco company wants to identify the customers who are likely to churn or leave the company. By understanding the characteristics and behavior patterns of these customers, the company can take proactive measures to prevent churn and implement targeted retention strategies.\n",
    "\n",
    "### Goals:\n",
    "\n",
    "- Develop a predictive model that can accurately identify customers who are likely to churn based on their profile information and service usage patterns.\n",
    "- Gain insights into the key factors or variables that are closely associated with customer churn, such as tenure, services subscribed, contract type, monthly charges, and customer demographics.\n",
    "- Use the insights and the predictive model to develop effective customer retention strategies and personalized offers or incentives to reduce churn.\n",
    "\n",
    "### Analytic Approach:\n",
    "\n",
    "- Perform exploratory data analysis (EDA) to understand the dataset, identify any missing or inconsistent data, and gain initial insights into potential relationships between features and customer churn.\n",
    "- Preprocess the data by handling missing values, encoding categorical variables, and scaling numerical features, if necessary.\n",
    "- Split the data into training and testing sets.\n",
    "- Build and evaluate various machine learning classification models (e.g., logistic regression, decision trees, random forests, gradient boosting) to predict customer churn.\n",
    "- Optimize the best-performing model(s) through techniques like hyperparameter tuning and ensemble methods.\n",
    "- Interpret the model results to identify the most important features influencing customer churn.\n",
    "- Validate the model's performance on the test set using appropriate evaluation metrics.\n",
    "\n",
    "### Metric Evaluation:\n",
    "The primary evaluation metric for this classification problem will be the Area Under the Receiver Operating Characteristic (ROC-AUC) curve. The ROC-AUC provides a comprehensive measure of the model's ability to distinguish between churners and non-churners across different classification thresholds.\n",
    "\n",
    "Additionally, we can consider other relevant metrics, such as:\n",
    "- Precision: The proportion of correctly identified churners among all predicted churners (to minimize false positives).\n",
    "- Recall: The proportion of correctly identified churners among all actual churners (to minimize false negatives).\n",
    "- F1-score: The harmonic mean of precision and recall, providing a balanced measure of model performance.\n",
    "The choice of metric(s) will depend on the business priorities and the relative importance of minimizing false positives (incorrectly identifying non-churners as churners) or false negatives (missing potential churners).\n",
    "\n",
    "By analyzing the model's performance using these metrics, the telco company can strike a balance between proactive customer retention efforts and efficient resource allocation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this approach, a Random Forest Classifier is used as the main algorithm. The data is preprocessed, oversampled, and feature selection is performed. Hyperparameter tuning is also done using GridSearchCV to find the best hyperparameters for the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"telcocucu.csv\")\n",
    "\n",
    "# Preprocess data\n",
    "categorical_cols = ['Dependents', 'OnlineSecurity', 'OnlineBackup', 'InternetService', 'DeviceProtection', 'TechSupport', 'Contract', 'PaperlessBilling']\n",
    "numerical_cols = ['tenure', 'MonthlyCharges']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the first line loads a CSV file into a Pandas DataFrame, and the next two lines identify which columns in the DataFrame contain categorical data and which columns contain numerical data. This information is typically needed for preprocessing the data before training a machine learning model, as categorical and numerical data often need to be handled differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Target Variable\n",
    "This step encodes the target variable 'Churn' using a LabelEncoder, which assigns a numerical label to each category. This is necessary because many machine learning algorithms require the target variable to be numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Churn'])\n",
    "\n",
    "# Split data into features and target\n",
    "X = df.drop('Churn', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for string values in features and encode them:\n",
    "This step checks if there are any string (object) columns in the feature matrix X. If such columns exist, they are encoded using a LabelEncoder, which assigns a numerical label to each category.\n",
    "\n",
    "This step creates a categorical_transformer pipeline that will one-hot encode categorical features using the OneHotEncoder. The handle_unknown='ignore' parameter ensures that any unknown categories in the test set are ignored during the encoding process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for string values in X\n",
    "string_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "\n",
    "# Encode string values in X\n",
    "if string_cols:\n",
    "    le = LabelEncoder()\n",
    "    for col in string_cols:\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define numerical transformer & combining transformer :\n",
    "This line defines a numerical_transformer, which is set to 'passthrough' for now. If any preprocessing is required for numerical features, it can be defined here.\n",
    "\n",
    "This step combines the categorical_transformer and numerical_transformer using the ColumnTransformer. The transformers parameter specifies which transformer to apply to which columns. categorical_cols and numerical_cols should be lists containing the names of categorical and numerical columns, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess numerical features (if needed)\n",
    "numerical_transformer = 'passthrough'\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "        ('num', numerical_transformer, numerical_cols)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the machine learning model:\n",
    "This step includes the following:\n",
    "\n",
    "1. Split the data into training and testing sets.\n",
    "2. Apply preprocessing (encoding, scaling, etc.) to the training and testing feature matrices.\n",
    "3. Oversample the minority class in the training data using SMOTE.\n",
    "4. Perform feature selection on the training data using a Random Forest Classifier.\n",
    "5. Create a pipeline with a Random Forest Classifier as the estimator.\n",
    "6. Perform hyperparameter tuning using GridSearchCV with cross-validation to find the best hyperparameters.\n",
    "7. Train the model with the best hyperparameters on the training data.\n",
    "8. Make predictions on the test set using the trained model.\n",
    "9. Evaluate the model's performance using various metrics (ROC-AUC, precision, recall, and F1-score).\n",
    "\n",
    "This step encompasses the core of the machine learning model training and evaluation process, including data preparation, model selection, hyperparameter tuning, and performance assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying preprocessing to feature matrix...\n",
      "Oversampling minority class...\n",
      "Performing feature selection...\n",
      "Preparing pipeline with Random Forest classifier...\n",
      "Performing hyperparameter tuning...\n",
      "Training model...\n",
      "[-] Training in progress...\n",
      "Training best model...\n",
      "\n",
      "Training successful!\n",
      "ROC-AUC: 0.76\n",
      "Precision: 0.60\n",
      "Recall: 0.71\n",
      "F1-score: 0.65\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply the preprocessing to the feature matrix\n",
    "print(\"Applying preprocessing to feature matrix...\")\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Oversample the minority class\n",
    "print(\"Oversampling minority class...\")\n",
    "smote = SMOTE()\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Perform feature selection\n",
    "print(\"Performing feature selection...\")\n",
    "selector = SelectFromModel(estimator=RandomForestClassifier(), threshold='median')\n",
    "X_train_selected = selector.fit_transform(X_train_resampled, y_train_resampled)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Prepare pipeline with Random Forest classifier\n",
    "print(\"Preparing pipeline with Random Forest classifier...\")\n",
    "classifier_pipeline = Pipeline(steps=[\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "print(\"Performing hyperparameter tuning...\")\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__n_estimators': [100, 200, 300]\n",
    "}\n",
    "grid_search = GridSearchCV(classifier_pipeline, param_grid, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"Training model...\")\n",
    "load_animation = \"|/-\\\\\"\n",
    "idx = 0\n",
    "start_time = datetime.now()\n",
    "\n",
    "while True:\n",
    "    current_time = datetime.now()\n",
    "    elapsed_time = current_time - start_time\n",
    "    if elapsed_time.total_seconds() > 60:\n",
    "        break\n",
    "\n",
    "    msg = f\"\\r[{load_animation[idx % len(load_animation)]}] Training in progress...\"\n",
    "    sys.stdout.write(msg)\n",
    "    sys.stdout.flush()\n",
    "    idx += 1\n",
    "    time.sleep(0.2)\n",
    "\n",
    "grid_search.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Get the best estimator\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Train the model\n",
    "print(\"\\nTraining best model...\")\n",
    "best_classifier.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_classifier.predict(X_test_selected)\n",
    "\n",
    "print(\"\\nTraining successful!\")\n",
    "\n",
    "# Evaluate the model\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"ROC-AUC: {roc_auc:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the provided evaluation metrics, we can draw the following conclusions and provide recommendations for the telco company:\n",
    "\n",
    "1. **Model Performance Analysis**:\n",
    "   - The ROC-AUC score of 0.75 indicates a reasonably good ability of the model to distinguish between customers who will churn and those who will not. However, there is still room for improvement.\n",
    "   - The precision score of 0.60 means that out of the customers predicted as churners, 60% of them are actually churners. This suggests that the model has a moderate level of precision in identifying true positives (churners).\n",
    "   - The recall score of 0.70 implies that the model is able to correctly identify 70% of the actual churners. While this is a decent recall rate, it also means that 30% of potential churners are being missed by the model.\n",
    "   - The F1-score of 0.65 provides a balanced view of the model's performance, taking into account both precision and recall. It indicates a moderate level of overall performance.\n",
    "\n",
    "2. **Recommendations for the Telco Company**:\n",
    "   - While the model shows promising results, there is still room for improvement. The company should continue to explore additional feature engineering, data preprocessing techniques, and alternative machine learning algorithms to enhance the model's predictive power.\n",
    "   - Given the moderate precision score, the company should exercise caution when targeting customers predicted as churners. It may be beneficial to prioritize those customers with the highest predicted probability of churning to optimize resource allocation and minimize the impact of false positives.\n",
    "   - The recall score suggests that the company may be missing a significant portion of potential churners. To address this, the company could consider adjusting the classification threshold or exploring ensemble methods that combine multiple models to improve recall without significantly compromising precision.\n",
    "   - The company should analyze the feature importance or model coefficients to gain insights into the most influential factors contributing to customer churn. This information can guide the development of targeted retention strategies and personalized offers or incentives for at-risk customers.\n",
    "   - Continuously monitoring and updating the model with new data is crucial, as customer behavior and market dynamics can change over time. Regular model retraining and evaluation should be implemented to ensure the model remains relevant and effective.\n",
    "\n",
    "3. **Conclusion on the Effectiveness of the Machine Learning Approach**:\n",
    "   The machine learning approach demonstrates its effectiveness in identifying potential churners and providing insights into the factors contributing to customer churn. However, the moderate performance metrics suggest that the problem domain may not be fully solved by this model alone.\n",
    "\n",
    "   To maximize the benefits of the machine learning approach, the telco company should consider integrating the model's predictions with additional data sources, such as customer feedback, market analysis, and domain expertise. By combining the model's insights with qualitative information and business knowledge, the company can develop more comprehensive and effective customer retention strategies.\n",
    "\n",
    "   Additionally, continuous model improvement through iterative feature engineering, algorithm selection, and parameter tuning will be essential to enhance the model's predictive capabilities and better address the customer churn problem over time.\n",
    "\n",
    "Overall, while the current machine learning model provides valuable insights and predictions, it should be viewed as part of a broader customer retention strategy that incorporates multiple data sources, domain knowledge, and ongoing model refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
